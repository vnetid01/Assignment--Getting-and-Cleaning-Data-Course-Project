---
title: 'Assignment: Getting and Cleaning Data Course project'
author: "Varun Tomar"
date: "April 17, 2016"
output: rmarkdown::html_vignette
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project Details:

The project requires following steps to be completed in order to generate required data set

- Merges the training and the test sets to create one data set.
- Extracts only the measurements on the mean and standard deviation for each measurement.
- Uses descriptive activity names to name the activities in the data set
- Appropriately labels the data set with descriptive variable names.
- From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.    
    
The project requirements for submission are as follows:

1. ***a tidy data set*** as described above, 
2. ***Github repository***-A link with your script for performing the analysis, and 
3. ***CodeBook.md***-A code book that describes the variables, the data, and any transformations . 
4. ***README.md***-in the repo with your scripts.

# Step 1 - Download the archive file and set working directory



```{r download and extract file}
file_url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
if(!file.exists("UCI.zip")){download.file(file_url,"UCI.zip")}
unzip("UCI.zip",exdir = "Data")
src_file<-paste(getwd(),"/","Data",sep="")
list.files(src_file,recursive = TRUE)
```

#Step 2 - Extract required files to define variables

###UCI Har dataset files
**Activity labels**

```{r activity labels}
act_lbs<-read.csv(paste(src_file,"/","UCI Har Dataset","/","activity_labels.txt",sep=""),header=FALSE,sep="",skipNul = TRUE)
names(act_lbs)<-c("code","lbls")
head(act_lbs)
```



**Features**

```{r features}
ftrs<-read.csv(paste(src_file,"/","UCI Har Dataset","/","features.txt",sep=""),header=FALSE,sep="",skipNul = TRUE)
head(ftrs)
```

###Test folder files
**extract files to test case variables**
```{r test variables}
X_ts<-read.csv(paste(src_file,"/","UCI Har Dataset","/","test","/","X_test.txt",sep=""),header=FALSE,sep="",skipNul = TRUE)
Y_ts<-read.csv(paste(src_file,"/","UCI Har Dataset","/","test","/","Y_test.txt",sep=""),header=FALSE,sep="",skipNul = TRUE)
s_ts<-read.csv(paste(src_file,"/","UCI Har Dataset","/","test","/","subject_test.txt",sep=""),header=FALSE,sep="",skipNul = TRUE)
names(s_ts)<-"sub"
names(Y_ts)<-"code"
names(X_ts)<-ftrs$V2
```

###Train folder files
**extract file to train case variables**

```{r train variables}
X_tr<-read.csv(paste(src_file,"/","UCI Har Dataset","/","train","/","X_train.txt",sep=""),header=FALSE,sep="",skipNul = TRUE)
Y_tr<-read.csv(paste(src_file,"/","UCI Har Dataset","/","train","/","Y_train.txt",sep=""),header=FALSE,sep="",skipNul = TRUE)
s_tr<-read.csv(paste(src_file,"/","UCI Har Dataset","/","train","/","subject_train.txt",sep=""),header=FALSE,sep="",skipNul = TRUE)
names(s_tr)<-"sub"
names(Y_tr)<-"code"
names(X_tr)<-ftrs$V2
```

#Step 3 - combine all files
###test files

**assign labels to test activity "Y_ts" variable**
```{r test activity labels identification}
lbs_ts<-merge(Y_ts,act_lbs,by="code",sort = F)
head(lbs_ts)

```
**align test case variables under single data set "test_data"**
**add identification column for test cases**
```{r test data set creation}
test_data<-cbind(lbs_ts,s_ts,X_ts,sort=F)

test_data$ID<-"test"
str(test_data)
```


###train files

**assign labels to train activity "Y_tr" variable**
```{r train activity labels identification}
lbs_tr<-merge(Y_tr,act_lbs,by="code",sort = F)
head(lbs_tr)
```
**align train case variables under single data set "train_data"**
**add identification column for train cases**

```{r train data set creation}
train_data<-cbind(lbs_tr,s_tr,X_tr,sort=F)
train_data$ID<-"train"
str(train_data)
```


###combine both data sets -all data

```{r Combine Test and Train data set}
all_data<-rbind(test_data,train_data)
```



#Step 4 - creating a tidy data set
###assign descriptive names

```{r descriptive variables names}
names(all_data)<-gsub("^t", "time", names(all_data))
names(all_data)<-gsub("^f", "frequency", names(all_data))
names(all_data)<-gsub("Acc", "Accelerometer", names(all_data))
names(all_data)<-gsub("Gyro", "Gyroscope", names(all_data))
names(all_data)<-gsub("Mag", "Magnitude", names(all_data))
names(all_data)<-gsub("BodyBody", "Body", names(all_data))
str(all_data)
```

###select only mean and std deviation variables for new data set

```{r select mean and standard deviation variables from data set}
library(tidyr)
new<-all_data[,c(1:3,grep("mean",colnames(all_data)),grep("std",colnames(all_data)))]
names(new)
```


#Step 5 - create a new data set 
###Criteria  - 
-Average of each variable for each activity 
-Average of each variable for each subject
```{r creating final data set based on criteria}
final<-aggregate(.~sub+code+lbls,new,mean)
final<-final[order(final$lbls,final$sub),]
str(final)
```



#Step 6 - load file as "codebook.Rmd"
```{r creating codebook}
library("knitr")
knit("run_analysis.R","codebook.Rmd")
```

